第5章 統計分析

統計的分布
観測するすべての変数はどのくらいの頻度で特定の値が現れるかという度数分布を形成する。
古典的な分布には以下の性質がある
・現実の世界で良く発生する度数分布の形を説明する
・ごく少数のパラメータによる閉形式を使って数学的に説明できる
特定のデータの観測を抽象化するとそのけっかは独立して研究する価値のある確率分布となる。

二項分布
二項分布：n回の特別な順序のない独立した試行でちょうどx回P1が発生する確率を示す
注目すべきポイントは以下
・離散的である
・恐らくこの分布の背後にある理論を説明できる
・ベル型の一種になる
・2個のパラメータだけで定義される

正規分布
非常に多くの情報がベル型の曲線でモデリングできる。
あらゆるベル型曲線の母はガウス分布、正規分布と呼ばれる
正規分布の注目すべきポイントは以下
・連続的である
・この分布がどこから導かれたのかを説明できない
・正規分布は本当にベル型になっている
・正規分布も2個のパラメータだけで定義される

正規分布に内在する意味
正規分布の性質を捉えるときには平均と標準偏差が役に立つ。

ポワソン分布
ポワソン分布はまれな事象が発生する間隔の頻度を測定する。

べき乗則分布
都市人口などは正規分布に従っておらずべき乗則という別の分布に従っている。
→ロングテールなグラフなど
人口の多い都市はほかの都市よりも多く人を集められるという状況のため。
べき乗則分布は不公平を反映している＝どこにでもある

分布からのサンプリング
確率分布に含まれる点のサンプリングはよく行われる操作
方法として逆関数法を用いたサンプリングと呼ばれる手法が一般的
Pythonでやるなら大体ライブラリは存在している

2次元以上からの無作為なサンプリング
分布から正しく標本を抽出するという問題は次元数が増えると面倒。

統計的有意性
強い相関があれば意味があるか？
→相関があるからといって因果関係があるわけではない

有意性の重要性
統計的有意性とは2つの分布の間には間違いなく違いがあるという自信の度合いを測ったもの
ただし統計的有意性はその違いの大きさや重要性を測るわけではない
大切なのは効果量（2つのグループの差の大きさ）
効果量を測定する統計量は以下
・コーエンのd
・ピアソンの相関係数r
・変動係数r^2
・重なりの割合

t検定
2つの標本の母平均が異なるかを評価する方法。A/Bテストでよく使う
以下の条件が満たされれば2つの平均の差は有意である
・平均の差が比較的大きい
・標準偏差が十分に小さい
・標本サイズが十分に多い

コルモゴロフ・スミルノフ検定（KS検定）
2つの標本分布の累積分布関数を比較して両者がどれくらい近いかを検証する

ボンフェローニ補正
科学の世界では統計的に優位かどうかの基準として伝統的にα＝0.05が使われている。
何種類もの仮説を試した場合はもっと高く基準を設ける必要がある。
ボンフェローニ補正は明らかに有意に見える統計量をどのくらい信用してもよいかを測る上で
重要である。
ボンフェローニ補正はn種類の異なる仮説を同時に試したときに水準αで有意だと考えるためには
基準値をα/nに下げなければならない。

誤検出率
ベンジャミーニ・ホッホベルク法は誤検出を最小限に抑えるための手法
方法はまずp値の強さによって変数をソートする＝極端な変数は左側、有意性の低い変数は右側に集まる。
次にこの順番の中でi位の変数について考える。
以下の条件が満たされる場合、優位性を認める
∀j^i=1(pj≦j/mα)

パーミュテーションテストとp値
従来の統計的有意性検定は2つの標本が同じ分布から得られたものかを判断するために
非常に効率的。
しかしこれらの検定が本来の力を発揮するには適切に実施される必要がある。
パーミュテーションテストなら一般性が高く微妙な問題を気にせずに有意性の有無を判断できる。

ランダムな順列の生成
ランダムな順列の生成もよく失敗する重要なサンプリング問題の1つ。

ベイズ推定
条件付き確率Ｐ（Ａ｜Ｂ）は事象Ｂが発生したことが分かっているときの事象Ａの尤度を測る。
条件付き確率を扱うときは条件を逆にしてくれるベイズの定理が重要な手法
P(A|B)=P(B|A)P(A)/P(B)
ベイズの定理を使えばＰ（結果｜データ）という問題をもっと簡単に計算できることが多い
Ｐ（データ｜結果）に変換できる。
